{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcwpGy8/mJWKQJDs+EEyse",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowrisankar393/vaylen-transitlk/blob/Multi-Sensor-Fusion-Crash-Detection/TransitLK_MSFCD_CVP_TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup & Environment"
      ],
      "metadata": {
        "id": "L_La6WtoY70J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l-YPTxUYA_6",
        "outputId": "be1f5331-626c-4e95-9567-942122799cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow Version: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from google.colab import files, drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(\"TensorFlow Version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Drive & Load Roboflow Dataset"
      ],
      "metadata": {
        "id": "-zUr1dzZZARO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#dataset\n",
        "DATASET_PATH = '/content/drive/MyDrive/TransitLK_MSFCD.v1i.multiclass'\n",
        "\n",
        "print(\"Dataset Path:\", DATASET_PATH)\n",
        "\n",
        "#verify structure\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    split_path = os.path.join(DATASET_PATH, split)\n",
        "    if os.path.exists(split_path):\n",
        "        print(f\"{split} folder found: {len(os.listdir(split_path))} files\")\n",
        "    else:\n",
        "        print(f\"{split} folder missing\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-RZsX9nyZBAB",
        "outputId": "044711e2-39b3-4729-cd63-a6bbd97dabc1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset Path: /content/drive/MyDrive/TransitLK_MSFCD.v1i.multiclass\n",
            "train folder missing\n",
            "valid folder missing\n",
            "test folder missing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & Parse Class Labels"
      ],
      "metadata": {
        "id": "jScMd5cFZCv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading Class Definitions\")\n",
        "\n",
        "#_classes.csv from train folder (Roboflow format)\n",
        "classes_csv = os.path.join(DATASET_PATH, 'train', '_classes.csv')\n",
        "\n",
        "if os.path.exists(classes_csv):\n",
        "    #_classes.csv is usually: class_name,class_id\n",
        "    class_df = pd.read_csv(classes_csv)\n",
        "    print(\"Class mapping:\")\n",
        "    print(class_df)\n",
        "\n",
        "    #create label dictionary\n",
        "    class_names = class_df['class_name'].tolist()\n",
        "    NUM_CLASSES = len(class_names)\n",
        "    CLASS_INDICES = range(NUM_CLASSES)\n",
        "\n",
        "    print(f\"\\nâœ… Found {NUM_CLASSES} classes:\")\n",
        "    for idx, name in enumerate(class_names):\n",
        "        print(f\"   {idx}: {name}\")\n",
        "else:\n",
        "    #if no _classes.csv\n",
        "    print(\"No _classes.csv found. Assuming binary classification (crash/normal)\")\n",
        "    class_names = ['normal', 'crash']\n",
        "    NUM_CLASSES = 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pu-gwPQhZEFQ",
        "outputId": "16f05176-15ca-46a5-bcaf-35ff65a9176c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Class Definitions\n",
            "No _classes.csv found. Assuming binary classification (crash/normal)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load & EDA - Image Data"
      ],
      "metadata": {
        "id": "0B5qffyaZF1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Exploratory Data Analysis\\n\")\n",
        "\n",
        "def load_images_from_folder(folder_path, label):\n",
        "    #load images and labels from folder\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder_path):\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            img_path = os.path.join(folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            images.append(img)\n",
        "            labels.append(label)\n",
        "    return images, labels\n",
        "\n",
        "#load sample of data for EDA\n",
        "SAMPLE_SIZE = 50\n",
        "\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for idx, class_name in enumerate(class_names):\n",
        "    class_folder = os.path.join(DATASET_PATH, 'train', class_name)\n",
        "\n",
        "    if os.path.exists(class_folder):\n",
        "        #subfolders of classes\n",
        "        images, labels = load_images_from_folder(class_folder, idx)\n",
        "        all_images.extend(images[:SAMPLE_SIZE//NUM_CLASSES])\n",
        "        all_labels.extend(labels[:SAMPLE_SIZE//NUM_CLASSES])\n",
        "        print(f\"Loaded {len(images)} images for class '{class_name}'\")\n",
        "    else:\n",
        "        print(f\"Folder not found: {class_folder}\")\n",
        "\n",
        "print(f\"\\nTotal loaded: {len(all_images)} images\")\n",
        "\n",
        "#display sample images\n",
        "plt.figure(figsize=(15, 5))\n",
        "for i in range(min(15, len(all_images))):\n",
        "    plt.subplot(3, 5, i+1)\n",
        "    plt.imshow(all_images[i])\n",
        "    plt.title(f\"Class: {class_names[all_labels[i]]}\")\n",
        "    plt.axis('off')\n",
        "plt.suptitle('Sample Training Images', fontsize=16)\n",
        "plt.show()\n",
        "\n",
        "#image statistics\n",
        "heights = [img.shape[0] for img in all_images]\n",
        "widths = [img.shape[1] for img in all_images]\n",
        "\n",
        "print(f\"\\nImage Statistics:\")\n",
        "print(f\"   Average height: {np.mean(heights):.0f}px\")\n",
        "print(f\"   Average width: {np.mean(widths):.0f}px\")\n",
        "print(f\"   Height range: {min(heights)}-{max(heights)}px\")\n",
        "print(f\"   Width range: {min(widths)}-{max(widths)}px\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "6oBGSwkhZHSj",
        "outputId": "3520f46f-1496-4a38-b6ee-564b8819e5a1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploratory Data Analysis\n",
            "\n",
            "Folder not found: /content/drive/MyDrive/TransitLK_MSFCD.v1i.multiclass/train/normal\n",
            "Folder not found: /content/drive/MyDrive/TransitLK_MSFCD.v1i.multiclass/train/crash\n",
            "\n",
            "Total loaded: 0 images\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Image Statistics:\n",
            "   Average height: nanpx\n",
            "   Average width: nanpx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "min() iterable argument is empty",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3034575134.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Average height: {np.mean(heights):.0f}px\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Average width: {np.mean(widths):.0f}px\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Height range: {min(heights)}-{max(heights)}px\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"   Width range: {min(widths)}-{max(widths)}px\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: min() iterable argument is empty"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Preprocessing & Augmentation"
      ],
      "metadata": {
        "id": "FAkkGmSjZIeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Data Preprocessing & Augmentation\\n\")\n",
        "\n",
        "#target image size for model\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#data augmentation for training to prevent overfitting\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(224, 224, 3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1),\n",
        "    layers.RandomContrast(0.1),\n",
        "])\n",
        "\n",
        "#preprocessing for validation/test\n",
        "preprocess_input = keras.applications.mobilenet_v2.preprocess_input\n",
        "\n",
        "print(f\"Image size set to: {IMG_SIZE}\")\n",
        "print(f\"Batch size: {BATCH_SIZE}\")\n",
        "\n",
        "#use keras for efficient loading\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#training generator with augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=preprocess_input,\n",
        "    horizontal_flip=True,\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1\n",
        ")\n",
        "\n",
        "#validation/test generator without augmentation\n",
        "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_PATH, 'train'),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_PATH, 'valid'),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_generator = val_datagen.flow_from_directory(\n",
        "    os.path.join(DATASET_PATH, 'test'),\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(f\"\\nData generators created:\")\n",
        "print(f\"   Train batches: {len(train_generator)}\")\n",
        "print(f\"   Val batches: {len(val_generator)}\")\n",
        "print(f\"   Test batches: {len(test_generator)}\")"
      ],
      "metadata": {
        "id": "ZkLvMj5zZKNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Class Imbalance"
      ],
      "metadata": {
        "id": "e9UeejseZLeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Handling Class Imbalance\\n\")\n",
        "\n",
        "#check class distribution\n",
        "print(\"\\nTraining set class distribution:\")\n",
        "class_counts = {i: 0 for i in range(NUM_CLASSES)}\n",
        "for i in range(len(train_generator)):\n",
        "    _, labels = train_generator[i]\n",
        "    for label in labels:\n",
        "        class_counts[np.argmax(label)] += 1\n",
        "\n",
        "for idx, count in class_counts.items():\n",
        "    print(f\"   {class_names[idx]}: {count} images\")\n",
        "\n",
        "#calculate class weights\n",
        "total = sum(class_counts.values())\n",
        "class_weights = {idx: total/(NUM_CLASSES * count) for idx, count in class_counts.items()}\n",
        "\n",
        "print(f\"\\nðŸ“Š Class Weights for training:\")\n",
        "for idx, weight in class_weights.items():\n",
        "    print(f\"   {class_names[idx]}: {weight:.2f}\")\n",
        "\n",
        "#save weights for later use\n",
        "with open('class_weights.json', 'w') as f:\n",
        "    json.dump(class_weights, f, indent=2)"
      ],
      "metadata": {
        "id": "fX4ge2XwZNgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build CNN Architecture"
      ],
      "metadata": {
        "id": "5ULo1IdYZO_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Building CNN Architecture\\n\")\n",
        "\n",
        "\n",
        "#Transfer Learning: MobileNetV2 (lightweight for mobile devices)*\n",
        "base_model = keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,  #don't include classification head\n",
        "    weights='imagenet'  #use pre-trained weights\n",
        ")\n",
        "\n",
        "#freeze base model initially\n",
        "base_model.trainable = False\n",
        "\n",
        "#build the full model\n",
        "model = keras.Sequential([\n",
        "    data_augmentation,\n",
        "    base_model,\n",
        "    layers.GlobalAveragePooling2D(),\n",
        "    layers.Dropout(0.3),  # Prevent overfitting\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(NUM_CLASSES, activation='softmax')\n",
        "])\n",
        "\n",
        "#compile with adam optimizer and categorical crossentropy\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy', keras.metrics.Precision(name='precision'),\n",
        "             keras.metrics.Recall(name='recall')]\n",
        ")\n",
        "\n",
        "print(\"Model architecture built:\")\n",
        "print(f\"   Base: MobileNetV2 (frozen)\")\n",
        "print(f\"   Trainable params: {model.trainable_variables}\")\n",
        "print(f\"   Classes: {NUM_CLASSES}\")\n",
        "print(f\"   Optimizer: Adam\")"
      ],
      "metadata": {
        "id": "BX7qErJyZQuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "Lne2PORnZRsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training CNN Model\\n\")\n",
        "\n",
        "#callbacks for better training\n",
        "reduce_lr = callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7\n",
        ")\n",
        "\n",
        "early_stop = callbacks.EarlyStopping(\n",
        "    monitor='val_loss', patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "#train model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=50,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=len(val_generator),\n",
        "    class_weight=class_weights,\n",
        "    callbacks=[reduce_lr, early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training complete!\")\n",
        "\n",
        "#plot training history\n",
        "def plot_training_history(history):\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "    #accuracy\n",
        "    axes[0,0].plot(history.history['accuracy'], label='Train')\n",
        "    axes[0,0].plot(history.history['val_accuracy'], label='Val')\n",
        "    axes[0,0].set_title('Model Accuracy', fontweight='bold')\n",
        "    axes[0,0].set_xlabel('Epoch')\n",
        "    axes[0,0].set_ylabel('Accuracy')\n",
        "    axes[0,0].legend()\n",
        "    axes[0,0].grid(True)\n",
        "\n",
        "    #loss\n",
        "    axes[0,1].plot(history.history['loss'], label='Train')\n",
        "    axes[0,1].plot(history.history['val_loss'], label='Val')\n",
        "    axes[0,1].set_title('Model Loss', fontweight='bold')\n",
        "    axes[0,1].set_xlabel('Epoch')\n",
        "    axes[0,1].set_ylabel('Loss')\n",
        "    axes[0,1].legend()\n",
        "    axes[0,1].grid(True)\n",
        "\n",
        "    #precision\n",
        "    axes[1,0].plot(history.history['precision'], label='Train')\n",
        "    axes[1,0].plot(history.history['val_precision'], label='Val')\n",
        "    axes[1,0].set_title('Precision', fontweight='bold')\n",
        "    axes[1,0].legend()\n",
        "    axes[1,0].grid(True)\n",
        "\n",
        "    #recall\n",
        "    axes[1,1].plot(history.history['recall'], label='Train')\n",
        "    axes[1,1].plot(history.history['val_recall'], label='Val')\n",
        "    axes[1,1].set_title('Recall', fontweight='bold')\n",
        "    axes[1,1].legend()\n",
        "    axes[1,1].grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "IULmgufVZTTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation & Confusion Matrix"
      ],
      "metadata": {
        "id": "MOPJm6CgZVIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Evaluating Model on Test Set\\n\")\n",
        "\n",
        "#evaluate on test set\n",
        "test_loss, test_acc, test_precision, test_recall = model.evaluate(\n",
        "    test_generator, steps=len(test_generator)\n",
        ")\n",
        "\n",
        "print(f\"\\nTest Accuracy: {test_acc:.2%}\")\n",
        "print(f\"   Precision: {test_precision:.2%}\")\n",
        "print(f\"   Recall: {test_recall:.2%}\")\n",
        "\n",
        "#predict on test set\n",
        "y_test_true = []\n",
        "y_test_pred = []\n",
        "\n",
        "for i in range(len(test_generator)):\n",
        "    X_batch, y_batch = test_generator[i]\n",
        "    preds = model.predict(X_batch)\n",
        "\n",
        "    y_test_true.extend(np.argmax(y_batch, axis=1))\n",
        "    y_test_pred.extend(np.argmax(preds, axis=1))\n",
        "\n",
        "#confusion Matrix\n",
        "cm = confusion_matrix(y_test_true, y_test_pred)\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "#visualize\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.title('Confusion Matrix - Test Set', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "#classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_true, y_test_pred,\n",
        "                            target_names=class_names))"
      ],
      "metadata": {
        "id": "simr4-XHZWIY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance & Model Interpretation"
      ],
      "metadata": {
        "id": "dQDDtTh3ZX-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Feature Importance & Model Interpretation\\n\")\n",
        "\n",
        "#visualize what the model sees using GradCAM\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "#extract the last convolutional layer\n",
        "last_conv_layer = base_model.get_layer('Conv_1')\n",
        "grad_model = Model([base_model.input], [last_conv_layer.output, model.output])\n",
        "\n",
        "def generate_gradcam(image_array, class_index):\n",
        "    \"\"\"Generate Grad-CAM heatmap for a specific class\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_output, predictions = grad_model(image_array)\n",
        "        loss = predictions[:, class_index]\n",
        "\n",
        "    grads = tape.gradient(loss, conv_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    conv_output = conv_output[0]\n",
        "    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_output), axis=-1)\n",
        "    heatmap = np.maximum(heatmap, 0)  #relu\n",
        "    heatmap /= np.max(heatmap)  #normalize\n",
        "\n",
        "    return heatmap\n",
        "\n",
        "#test on a sample crash image\n",
        "sample_image_path = os.path.join(DATASET_PATH, 'test', 'crash', os.listdir(os.path.join(DATASET_PATH, 'test', 'crash'))[0])\n",
        "sample_img = cv2.imread(sample_image_path)\n",
        "sample_img = cv2.cvtColor(sample_img, cv2.COLOR_BGR2RGB)\n",
        "sample_img_resized = cv2.resize(sample_img, IMG_SIZE)\n",
        "sample_array = np.expand_dims(sample_img_resized, axis=0).astype(np.float32)\n",
        "\n",
        "#get GradCAM\n",
        "crash_class_idx = class_names.index('crash') if 'crash' in class_names else 0\n",
        "heatmap = generate_gradcam(sample_array, crash_class_idx)\n",
        "\n",
        "#overlay heatmap on original image\n",
        "heatmap_resized = cv2.resize(heatmap, (sample_img.shape[1], sample_img.shape[0]))\n",
        "heatmap_resized = np.uint8(255 * heatmap_resized)\n",
        "heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "superimposed_img = cv2.addWeighted(sample_img, 0.6, heatmap_color, 0.4, 0)\n",
        "\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(sample_img)\n",
        "plt.title('Original Image', fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(heatmap, cmap='jet')\n",
        "plt.title('Grad-CAM Heatmap', fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title('Crash Focus Areas', fontweight='bold')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "print(\"Grad-CAM visualization complete!\")\n",
        "print(\"   Red areas = high activation for crash detection\")"
      ],
      "metadata": {
        "id": "Fkl-fRJHZY-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Model"
      ],
      "metadata": {
        "id": "Pb3mltZbZatr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Exporting Model\\n\")\n",
        "\n",
        "#save the complete model\n",
        "MODEL_FILENAME = \"TransitLK-MSFCD-CV-XGB-1.h5\"\n",
        "model.save(MODEL_FILENAME)\n",
        "\n",
        "#convert to TensorFlow Lite for mobile deployment\n",
        "print(\"\\nConverting to TensorFlow Lite (for mobile)\")\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]  #optimize for size/speed\n",
        "converter.target_spec.supported_types = [tf.float16]  #use float16 for faster inference\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "TFLITE_FILENAME = \"TransitLK-MSFCD-CV-XGB-1.tflite\"\n",
        "with open(TFLITE_FILENAME, 'wb') as f:\n",
        "    f.write(tflite_model)\n",
        "\n",
        "print(f\"Keras model saved: {MODEL_FILENAME}\")\n",
        "print(f\"TensorFlow Lite model saved: {TFLITE_FILENAME}\")\n",
        "print(f\"   Model size: {len(tflite_model) / 1024:.2f} KB\")\n",
        "\n",
        "#save class names for inference\n",
        "with open('cv_class_names.json', 'w') as f:\n",
        "    json.dump({'classes': class_names}, f)\n",
        "\n",
        "print(\"\\nFiles to download:\")\n",
        "print(f\"   1. {MODEL_FILENAME} (Keras format)\")\n",
        "print(f\"   2. {TFLITE_FILENAME} (Mobile-optimized)\")\n",
        "print(f\"   3. cv_class_names.json (Class mapping)\")"
      ],
      "metadata": {
        "id": "Elctzho2ZcIM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}