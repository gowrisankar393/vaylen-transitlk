{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBDGNyRsPbnF25QS069iGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gowrisankar393/vaylen-transitlk/blob/Multi-Sensor-Fusion-Crash-Detection/TransitLK_MSFCD_SDP_XGB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup & Data Loading"
      ],
      "metadata": {
        "id": "x5nFMtTxMdxA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmX9XW0GMX6B"
      },
      "outputs": [],
      "source": [
        "# üì¶ Install and import libraries\n",
        "!pip install xgboost scikit-learn pandas numpy matplotlib seaborn imbalanced-learn -q\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from imblearn.over_sampling import SMOTE  # For balancing crashes\n",
        "import xgboost as xgb\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ All libraries loaded successfully!\")\n",
        "\n",
        "# üìÇ Upload your dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()  # This will prompt you to select nthsc_telemetry_records.csv\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('nthsc_telemetry_records.csv')\n",
        "print(f\"üìä Dataset loaded: {df.shape[0]} rows, {df.shape[1]} columns\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "zHT_PeqCMghB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Exploratory Data Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Basic info\n",
        "print(\"\\n1. Dataset Info:\")\n",
        "df.info()\n",
        "\n",
        "print(\"\\n2. Missing Values:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "print(\"\\n3. Class Distribution (Crash vs Non-Crash):\")\n",
        "crash_counts = df['crash_label'].value_counts()\n",
        "print(crash_counts)\n",
        "print(f\"\\nCrash rate: {crash_counts[1]/len(df):.2%}\")\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.barplot(x=crash_counts.index, y=crash_counts.values, palette=['#96d46c','#ef4444'])\n",
        "plt.title('Class Distribution: Crash vs Non-Crash', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Crash Label (0=Normal, 1=Crash)')\n",
        "plt.ylabel('Count')\n",
        "for i, v in enumerate(crash_counts.values):\n",
        "    plt.text(i, v + 50, str(v), ha='center', fontweight='bold')\n",
        "plt.show()\n",
        "\n",
        "# Sensor statistics\n",
        "print(\"\\n4. Sensor Statistics:\")\n",
        "sensor_cols = [col for col in df.columns if col not in ['timestamp', 'crash_label']]\n",
        "print(df[sensor_cols].describe())"
      ],
      "metadata": {
        "id": "eYd44SbCMieO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Cleaning & Preprocessing"
      ],
      "metadata": {
        "id": "0mir_RN8MkQh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üßπ Data Cleaning & Preprocessing\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Copy to avoid modifying original\n",
        "df_clean = df.copy()\n",
        "\n",
        "# Handle missing values (if any)\n",
        "print(\"\\n1. Checking for missing values...\")\n",
        "missing_before = df_clean.isnull().sum().sum()\n",
        "df_clean = df_clean.fillna(df_clean.median())  # Fill with median\n",
        "missing_after = df_clean.isnull().sum().sum()\n",
        "print(f\"Missing values: {missing_before} ‚Üí {missing_after}\")\n",
        "\n",
        "# Convert timestamp to proper format (optional, for time-series features)\n",
        "print(\"\\n2. Parsing timestamps...\")\n",
        "df_clean['timestamp_seconds'] = df_clean['timestamp'].apply(\n",
        "    lambda x: float(x.split(':')[0]) * 60 + float(x.split(':')[1])\n",
        ")\n",
        "print(\"‚úÖ Timestamps converted to seconds\")\n",
        "\n",
        "# Separate features and target\n",
        "X = df_clean.drop(columns=['timestamp', 'crash_label'])\n",
        "y = df_clean['crash_label']\n",
        "\n",
        "print(f\"\\n3. Feature matrix shape: {X.shape}\")\n",
        "print(f\"   Target vector shape: {y.shape}\")\n",
        "\n",
        "# Mobile sensor subset (what your phone can actually measure)\n",
        "MOBILE_FEATURES = [\n",
        "    'accel_x', 'accel_y', 'accel_z',\n",
        "    'gyro_x', 'gyro_y', 'gyro_z',\n",
        "    'gps_lat', 'gps_lon', 'gps_speed'\n",
        "]\n",
        "\n",
        "X_mobile = X[MOBILE_FEATURES]\n",
        "print(f\"\\n4. Mobile features selected: {len(MOBILE_FEATURES)} features\")\n",
        "print(\"   Features:\", MOBILE_FEATURES)"
      ],
      "metadata": {
        "id": "HIg5dcT6Ml04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Class Imbalance"
      ],
      "metadata": {
        "id": "wehCSV-GMnYj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"‚öñÔ∏è Balancing Crash vs Non-Crash Data\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"\\nBefore balancing:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# Use SMOTE to generate synthetic crash examples\n",
        "smote = SMOTE(random_state=42, k_neighbors=3)\n",
        "X_balanced, y_balanced = smote.fit_resample(X_mobile, y)\n",
        "\n",
        "print(f\"\\nAfter SMOTE balancing:\")\n",
        "print(f\"Non-crash: {sum(y_balanced == 0)}\")\n",
        "print(f\"Crash: {sum(y_balanced == 1)}\")\n",
        "print(f\"New shape: {X_balanced.shape}\")\n",
        "\n",
        "# Verify the balance\n",
        "plt.figure(figsize=(8,5))\n",
        "balanced_counts = pd.Series(y_balanced).value_counts()\n",
        "sns.barplot(x=balanced_counts.index, y=balanced_counts.values, palette=['#96d46c','#ef4444'])\n",
        "plt.title('Balanced Class Distribution', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Crash Label')\n",
        "plt.ylabel('Count')\n",
        "for i, v in enumerate(balanced_counts.values):\n",
        "    plt.text(i, v - 500, str(v), ha='center', fontweight='bold', color='white')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8h_QtYkVMoxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Engineering & Selection"
      ],
      "metadata": {
        "id": "FPGtEA6KMqLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîß Feature Engineering\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Calculate derived features that help crash detection\n",
        "X_engineered = X_balanced.copy()\n",
        "\n",
        "# 1. Acceleration magnitude (total G-force)\n",
        "X_engineered['accel_magnitude'] = np.sqrt(\n",
        "    X_engineered['accel_x']**2 + X_engineered['accel_y']**2 + X_engineered['accel_z']**2\n",
        ")\n",
        "\n",
        "# 2. Gyroscope magnitude (total rotation)\n",
        "X_engineered['gyro_magnitude'] = np.sqrt(\n",
        "    X_engineered['gyro_x']**2 + X_engineered['gyro_y']**2 + X_engineered['gyro_z']**2\n",
        ")\n",
        "\n",
        "# 3. Speed change (jerk) - but we only have instant speed, so we'll use absolute speed\n",
        "X_engineered['gps_speed_abs'] = np.abs(X_engineered['gps_speed'])\n",
        "\n",
        "print(\"‚úÖ Engineered features:\")\n",
        "print(\"   - accel_magnitude (total acceleration force)\")\n",
        "print(\"   - gyro_magnitude (total rotation force)\")\n",
        "print(\"   - gps_speed_abs (absolute speed)\")\n",
        "\n",
        "# Select final features (including engineered ones)\n",
        "FINAL_FEATURES = MOBILE_FEATURES + ['accel_magnitude', 'gyro_magnitude', 'gps_speed_abs']\n",
        "X_final = X_engineered[FINAL_FEATURES]\n",
        "\n",
        "print(f\"\\nüìä Final feature matrix: {X_final.shape[1]} features\")\n",
        "print(\"   Features:\", FINAL_FEATURES)"
      ],
      "metadata": {
        "id": "gg6f8xQCMrfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train XGBoost Model"
      ],
      "metadata": {
        "id": "xrmAlB6gMvoa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üöÄ Training XGBoost Crash Detection Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_final, y_balanced, test_size=0.2, random_state=42, stratify=y_balanced\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Initialize XGBoost with parameters tuned for mobile sensors\n",
        "model = xgb.XGBClassifier(\n",
        "    n_estimators=150,           # More trees for better accuracy\n",
        "    max_depth=6,                # Allow deeper trees\n",
        "    learning_rate=0.05,         # Slower learning for better generalization\n",
        "    subsample=0.8,              # Use 80% of data per tree\n",
        "    colsample_bytree=0.8,       # Use 80% of features per tree\n",
        "    scale_pos_weight=1,         # Already balanced\n",
        "    random_state=42,\n",
        "    eval_metric='logloss'\n",
        ")\n",
        "\n",
        "print(\"\\nüìà Training in progress...\")\n",
        "# Train with early stopping to prevent overfitting\n",
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    early_stopping_rounds=20,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Training complete! Best iteration: {model.best_iteration}\")"
      ],
      "metadata": {
        "id": "pZXd7_kqMwD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation & Confusion Matrix"
      ],
      "metadata": {
        "id": "81IH_q_FMxMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üìä Model Evaluation\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_prob = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"\\nüéØ Test Accuracy: {accuracy:.2%}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"\\nüìã Classification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Normal', 'Crash']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"\\nüî¢ Confusion Matrix:\")\n",
        "print(cm)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Crash'],\n",
        "            yticklabels=['Normal', 'Crash'])\n",
        "plt.title('Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve (optional but useful)\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve', fontsize=14, fontweight='bold')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_Vwhl1tGMyUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Importance Analysis"
      ],
      "metadata": {
        "id": "T7vIuHzDNDuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üîç Feature Importance Analysis\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Get feature importance from XGBoost\n",
        "importance_df = pd.DataFrame({\n",
        "    'feature': FINAL_FEATURES,\n",
        "    'importance': model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Most Important Features:\")\n",
        "print(importance_df.head())\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.barplot(data=importance_df.head(10), x='importance', y='feature', palette='viridis')\n",
        "plt.title('Top 10 Feature Importances for Crash Detection', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Importance Score')\n",
        "plt.ylabel('Feature')\n",
        "plt.show()\n",
        "\n",
        "# Show correlation with crash label\n",
        "print(\"\\nüìà Correlation with Crash Label:\")\n",
        "correlations = X_final.apply(lambda x: x.corr(y_balanced))\n",
        "correlations_sorted = correlations.abs().sort_values(ascending=False)\n",
        "print(correlations_sorted.head(10))"
      ],
      "metadata": {
        "id": "H9fK9rb7NEWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export Model for Android\n"
      ],
      "metadata": {
        "id": "Z3HWeBC1NFdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üíæ Exporting Production Model\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Final model filename (matches your GitHub branch)\n",
        "MODEL_FILENAME = \"TransitLK-MSFCD-SCD-XGB-1.pkl\"\n",
        "\n",
        "# Save the trained model\n",
        "joblib.dump(model, MODEL_FILENAME)\n",
        "\n",
        "# Save feature order (CRITICAL for Android)\n",
        "feature_order_dict = {\n",
        "    'model_name': 'Multi-Sensor Fusion Crash Detection v1',\n",
        "    'features': FINAL_FEATURES,\n",
        "    'threshold': 0.75,\n",
        "    'accuracy': float(accuracy),\n",
        "    'git_branch': 'Multi-Sensor-Fusion-Crash-Detection'\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('model_metadata.json', 'w') as f:\n",
        "    json.dump(feature_order_dict, f, indent=2)\n",
        "\n",
        "print(f\"\\n‚úÖ Model saved: {MODEL_FILENAME}\")\n",
        "print(f\"‚úÖ Metadata saved: model_metadata.json\")\n",
        "print(f\"\\nüìã FINAL FEATURE ORDER for Android:\")\n",
        "for i, feat in enumerate(FINAL_FEATURES, 1):\n",
        "    print(f\"  {i}. {feat}\")\n",
        "\n",
        "print(\"\\nüìå NEXT STEPS:\")\n",
        "print(\"1. Download both files from Colab file panel\")\n",
        "print(\"2. Place them in your GitHub repo: vaylen-transitlk/Multi-Sensor-Fusion-Crash-Detection\")\n",
        "print(\"3. Update server.py to load this model\")\n",
        "print(\"4. Update Android app with your computer's IP address\")"
      ],
      "metadata": {
        "id": "c1ejukBUNHEy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}